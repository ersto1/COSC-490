# -*- coding: utf-8 -*-
"""Baltimore1Building1Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14DgOcOvckgVHVK-Yy26xBSSWGbaq07oM
"""

import pandas as pd
data = pd.read_csv("Buildings_Footprint.csv")
data

import pandas as pd
from pandas import read_csv
to_drop = ['OBJECTID_1', 'TAG', 'SUBTYPE','SRCDATE','SYMBOL','Shape_Leng','Override','RuleID_1','Override_1','GlobalID','URL','Shape__Area','Shape__Length']
df = pd.read_csv("Buildings_Footprint.csv")
df.drop(to_drop, inplace=True, axis=1)
df.head()

import matplotlib.pyplot as plt
column = df["AREA_"]
type(column)
column.plot(kind="hist")
plt.show()

import matplotlib.pyplot as plt
column = df["AREA_"]
type(column)
column.plot(kind="box")
plt.show()

import matplotlib.pyplot as plt
column = df["PERIMETER"]
type(column)
column.plot(kind="box")
plt.show()

# Scatter Plot Matrix
import matplotlib.pyplot as plt
import pandas
from pandas.plotting import scatter_matrix
url = "Buildings_Footprints1.csv"
names = ['1', '2', '3', '4', '5']
data = pandas.read_csv(url, names=names)
scatter_matrix(data)
plt.show()

import pandas as pd
url = ("Buildings_Footprints1.csv")
df = pd.read_csv(url)
type(df)
df.head()

boxplot = df.boxplot(figsize = (5,7))

# Grid Search for Algorithm Tuning
from pandas import read_csv
import numpy
from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV
url = "Buildings_Footprints1.csv"
names = ['1', '2', '3', '4', '5']
dataframe = read_csv(url, names=names)
array = dataframe.values
X = array[:,0:5]
Y = array[:,4]
alphas = numpy.array([1,0.1,0.01,0.001,0.0001,0])
param_grid = dict(alpha=alphas)
model = Ridge()
grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)
grid.fit(X, Y)
print(grid.best_score_)
print(grid.best_estimator_.alpha)

from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
url = "Buildings_Footprints1.csv"
names = ['1', '2', '3', '4', '5']
dataframe = read_csv(url, names=names)
array = dataframe.values
X = array[:,0:5]
Y = array[:,4]
kfold = KFold(n_splits=2, random_state=5, shuffle=True)
model = LogisticRegression(solver='liblinear')
results = cross_val_score(model, X, Y, cv=kfold)
print("Accuracy: %.3f%% (%.3f%%)" % (results.mean()*100.0, results.std()*100.0))

# 6
from sklearn.preprocessing import StandardScaler
import pandas
import numpy
from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
import pandas as pd
url = "Buildings_Footprints1.csv"
names = ['1', '2', '3', '4', '5']
dataframe = read_csv(url, names=names)
array = dataframe.values
X = array[:,0:5]
Y = array[:,4]
scaler = StandardScaler().fit(X)
rescaledX = scaler.transform(X)
# summarize transformed data
numpy.set_printoptions(precision=3)
print(rescaledX[0:5,:])

# Evaluate using Cross Validation
from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
url = "Buildings_Footprints1.csv"
names = ['1', '2', '3', '4', '5']
dataframe = read_csv(url, names=names)
array = dataframe.values
X = array[:,0:5]
Y = array[:,4]
kfold = KFold(n_splits=10, random_state=4, shuffle=True)
model = LogisticRegression(solver='liblinear')
results = cross_val_score(model, X, Y, cv=kfold)
print("Accuracy: %.3f%% (%.3f%%)" % (results.mean()*100.0, results.std()*100.0))

# Cross Validation Classification LogLoss
from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
url = "Buildings_Footprints1.csv"
names = ['1', '2', '3', '4', '5']
dataframe = read_csv(url, names=names)
array = dataframe.values
X = array[:,0:5]
Y = array[:,1]
kfold = KFold(n_splits=10, random_state=None)
model = LogisticRegression(solver='liblinear')
scoring = 'neg_log_loss'
results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
print('Logloss: %.3f (%.3f))' % (results.mean(), results.std()))

# KNN Regression
from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsRegressor
url = "Buildings_Footprints1.csv"
names = ['1', '2', '3', '4', '5']
dataframe = read_csv(url, delim_whitespace=True, names=names)
array = dataframe.values
X = array[:,0:5]
Y = array[:,4]
kfold = KFold(n_splits=10, random_state=None)
model = KNeighborsRegressor()
scoring = 'neg_mean_squared_error'
results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
print(results.mean())

# Compare Algorithms
from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
# load dataset
url = "Buildings_Footprints1.csv"
names = ['1', '2', '3', '4', '5']
dataframe = read_csv(url, names=names)
array = dataframe.values
X = array[:,0:5]
Y = array[:,4]
# prepare models
models = []
models.append(('LR', LogisticRegression(solver='liblinear')))
models.append(('LDA', LinearDiscriminantAnalysis()))
# evaluate each model in turn
results = []
names = []
scoring = 'accuracy'
for name, model in models:
	kfold = KFold(n_splits=10, random_state=None)
	cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)
	results.append(cv_results)
	names.append(name)
	msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
	print(msg)

# Grid Search for Algorithm Tuning
from pandas import read_csv
import numpy
from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV
url = "Buildings_Footprints1.csv"
names = ['1', '2', '3', '4', '5']
dataframe = read_csv(url, names=names)
array = dataframe.values
X = array[:,0:5]
Y = array[:,4]
alphas = numpy.array([1,0.1,0.01,0.001,0.0001,0])
param_grid = dict(alpha=alphas)
model = Ridge()
grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)
grid.fit(X, Y)
print(grid.best_score_)
print(grid.best_estimator_.alpha)

# Random Forest Classification
from pandas import read_csv
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
url = "Buildings_Footprints1.csv"
names = ['1', '2', '3', '4', '5']
dataframe = read_csv(url, names=names)
array = dataframe.values
X = array[:,0:5]
Y = array[:,1]
num_trees = 100
max_features = 5
kfold = KFold(n_splits=10, random_state=None)
model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)
results = cross_val_score(model, X, Y, cv=kfold)
print(results.mean())